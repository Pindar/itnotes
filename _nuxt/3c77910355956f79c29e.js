(window.webpackJsonp=window.webpackJsonp||[]).push([[60],{250:function(e,t){e.exports={body:'In my previous post about [How to setup rsyslog, elasticsearch and kibana on CoreOS and AWS](http://www.itnotes.de/coreos/deployment/tools/infrastructure/aws/docker/fleet/2015/04/03/how-to-setup-rsyslog-elasticsearch-kibana-on-coreos/) I used some custom scripts in order each service discovers all the required ones. E.g. I wrote my own announcement mechanism which polluted all the systemd unit files of the services. The disadvantage of my first approach is clear: it\'s mixing responsibilities.\n\nIn times of microservices and single responsibilities it has to be a better way to deal with it and in fact after doing some research (also talking with pkircher on the coreos IRC channel) I came up with the following:\n\n1. [Registrator](https://github.com/gliderlabs/registrator) (as docker container) runs on each server once and automatically register/deregisters services for Docker containers based on published ports and metadata from the container environment.\n2. [SkyDNS](https://github.com/skynetservices/skydns) (as docker container) runs on each server once and provides DNS to discover available services.\n3. [Logspout](https://github.com/gliderlabs/logspout) (as docker container) runs also on each server once and ships docker logs to a centralized syslog server.\n\nWhen a service comes online the following happens:\n\n<div class="diagram">\nmyService->DockerDeamon: start container\nRegistrator--\x3eDockerDeamon: listen\nRegistrator->etcd: writes an entry\nSkyDNS--\x3eetcd: updates dns\nLogspout--\x3eDockerDeamon: read logs\n</div>\n\nThe big advantage with this setup is that both the service discovery and the log shipping (through logspout) are completely decoupled from the application and still everything is dockerized - no further requirements on the host.\n\nThe simplified elasticsearch systemd-unit file can look like this:\n\n<pre>\n<code class="bash">\n[Unit]\nDescription=ElasticSearch service\nAfter=docker.service\n\n[Service]\nTimeoutSec=0\nEnvironmentFile=/etc/environment\n\nExecStartPre=/usr/bin/mkdir -p /vol/data/elasticsearch\nExecStartPre=/usr/bin/docker pull dockerfile/elasticsearch\n\nExecStart=/bin/bash -c \'\\\n  exec docker run \\\n  --name %p-%i \\\n  -h `hostname` \\\n  --publish 9200:9200 \\\n  --publish 9300:9300 \\\n  --volume /vol/data/elasticsearch:/usr/share/elasticsearch/data \\\n  -e SERVICE_ID=%p%i \\\n  -e ES_HEAP_SIZE=512M \\\n  --dns ${COREOS_PRIVATE_IPV4} \\\n  --dns-search=example.local \\\n  elasticsearch:1.5.2 \\\n  elasticsearch \\\n  --node.name=%p-%i \\\n  --cluster.name=logstash \\\n  --network.publish_host=${COREOS_PRIVATE_IPV4} \\\n  --discovery.zen.ping.multicast.enabled=false \\\n  --discovery.zen.ping.unicast.hosts=elasticsearch-9200.staging.example.local\'\n\nExecStop=/usr/bin/docker stop %p-%i\nExecStop=/usr/bin/docker rm %p-%i\n\n[X-Fleet]\nConflicts=%p@*.service\n</code>\n</pre>\n\nIt\'s just a simple reference to the unicast host of the "load balanced" skydns image route. Because one of the nice out of the box features of skydns is that it provides automatically round robin balancing of multiple registered docker-container from the same docker-image.\n\n[You can find the updated code about the rsyslog/elasticsearch/kibana setup on github](https://github.com/Pindar/coreos-demo/releases/tag/v0.2).\n\n----------\n\nAnd because I like it this is written with [StackEdit](https://stackedit.io/).\n\n\x3c!-- <script>\n$(".diagram").sequenceDiagram({theme: \'simple\'});\n<\/script> --\x3e\n',html:'<p>In my previous post about <a href="http://www.itnotes.de/coreos/deployment/tools/infrastructure/aws/docker/fleet/2015/04/03/how-to-setup-rsyslog-elasticsearch-kibana-on-coreos/">How to setup rsyslog, elasticsearch and kibana on CoreOS and AWS</a> I used some custom scripts in order each service discovers all the required ones. E.g. I wrote my own announcement mechanism which polluted all the systemd unit files of the services. The disadvantage of my first approach is clear: it\'s mixing responsibilities.</p>\n<p>In times of microservices and single responsibilities it has to be a better way to deal with it and in fact after doing some research (also talking with pkircher on the coreos IRC channel) I came up with the following:</p>\n<ol>\n<li><a href="https://github.com/gliderlabs/registrator">Registrator</a> (as docker container) runs on each server once and automatically register/deregisters services for Docker containers based on published ports and metadata from the container environment.</li>\n<li><a href="https://github.com/skynetservices/skydns">SkyDNS</a> (as docker container) runs on each server once and provides DNS to discover available services.</li>\n<li><a href="https://github.com/gliderlabs/logspout">Logspout</a> (as docker container) runs also on each server once and ships docker logs to a centralized syslog server.</li>\n</ol>\n<p>When a service comes online the following happens:</p>\n<div class="diagram">\nmyService->DockerDeamon: start container\nRegistrator--\x3eDockerDeamon: listen\nRegistrator->etcd: writes an entry\nSkyDNS--\x3eetcd: updates dns\nLogspout--\x3eDockerDeamon: read logs\n</div>\n<p>The big advantage with this setup is that both the service discovery and the log shipping (through logspout) are completely decoupled from the application and still everything is dockerized - no further requirements on the host.</p>\n<p>The simplified elasticsearch systemd-unit file can look like this:</p>\n<pre>\n<code class="bash">\n[Unit]\nDescription=ElasticSearch service\nAfter=docker.service\n\n[Service]\nTimeoutSec=0\nEnvironmentFile=/etc/environment\n\nExecStartPre=/usr/bin/mkdir -p /vol/data/elasticsearch\nExecStartPre=/usr/bin/docker pull dockerfile/elasticsearch\n\nExecStart=/bin/bash -c \'\\\n  exec docker run \\\n  --name %p-%i \\\n  -h `hostname` \\\n  --publish 9200:9200 \\\n  --publish 9300:9300 \\\n  --volume /vol/data/elasticsearch:/usr/share/elasticsearch/data \\\n  -e SERVICE_ID=%p%i \\\n  -e ES_HEAP_SIZE=512M \\\n  --dns ${COREOS_PRIVATE_IPV4} \\\n  --dns-search=example.local \\\n  elasticsearch:1.5.2 \\\n  elasticsearch \\\n  --node.name=%p-%i \\\n  --cluster.name=logstash \\\n  --network.publish_host=${COREOS_PRIVATE_IPV4} \\\n  --discovery.zen.ping.multicast.enabled=false \\\n  --discovery.zen.ping.unicast.hosts=elasticsearch-9200.staging.example.local\'\n\nExecStop=/usr/bin/docker stop %p-%i\nExecStop=/usr/bin/docker rm %p-%i\n\n[X-Fleet]\nConflicts=%p@*.service\n</code>\n</pre>\n<p>It\'s just a simple reference to the unicast host of the &quot;load balanced&quot; skydns image route. Because one of the nice out of the box features of skydns is that it provides automatically round robin balancing of multiple registered docker-container from the same docker-image.</p>\n<p><a href="https://github.com/Pindar/coreos-demo/releases/tag/v0.2">You can find the updated code about the rsyslog/elasticsearch/kibana setup on github</a>.</p>\n<hr>\n<p>And because I like it this is written with <a href="https://stackedit.io/">StackEdit</a>.</p>\n\x3c!-- <script>\n$(".diagram").sequenceDiagram({theme: \'simple\'});\n<\/script> --\x3e\n',attributes:{layout:"post",title:"Responsive infrastructure - Service discovery and log shipping with docker (3)",date:"2015-06-14T00:00:00.000Z",categories:"coreos deployment tools infrastructure aws docker fleet discovery",comments:!0,_meta:{resourcePath:"/home/travis/build/Pindar/itnotes/contents/posts/2015-06-14-service-discovery-and-log-shipping-with-docker.md"}},vue:{render:"return function render() { var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _vm._m(0) }",staticRenderFns:'return [function () { var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c(\'div\',{staticClass:"dynamicMarkdown"},[_c(\'p\',[_vm._v("In my previous post about "),_c(\'a\',{attrs:{"href":"http://www.itnotes.de/coreos/deployment/tools/infrastructure/aws/docker/fleet/2015/04/03/how-to-setup-rsyslog-elasticsearch-kibana-on-coreos/"}},[_vm._v("How to setup rsyslog, elasticsearch and kibana on CoreOS and AWS")]),_vm._v(" I used some custom scripts in order each service discovers all the required ones. E.g. I wrote my own announcement mechanism which polluted all the systemd unit files of the services. The disadvantage of my first approach is clear: it\'s mixing responsibilities.")]),_vm._v(" "),_c(\'p\',[_vm._v("In times of microservices and single responsibilities it has to be a better way to deal with it and in fact after doing some research (also talking with pkircher on the coreos IRC channel) I came up with the following:")]),_vm._v(" "),_c(\'ol\',[_c(\'li\',[_c(\'a\',{attrs:{"href":"https://github.com/gliderlabs/registrator"}},[_vm._v("Registrator")]),_vm._v(" (as docker container) runs on each server once and automatically register/deregisters services for Docker containers based on published ports and metadata from the container environment.")]),_vm._v(" "),_c(\'li\',[_c(\'a\',{attrs:{"href":"https://github.com/skynetservices/skydns"}},[_vm._v("SkyDNS")]),_vm._v(" (as docker container) runs on each server once and provides DNS to discover available services.")]),_vm._v(" "),_c(\'li\',[_c(\'a\',{attrs:{"href":"https://github.com/gliderlabs/logspout"}},[_vm._v("Logspout")]),_vm._v(" (as docker container) runs also on each server once and ships docker logs to a centralized syslog server.")])]),_vm._v(" "),_c(\'p\',[_vm._v("When a service comes online the following happens:")]),_vm._v(" "),_c(\'div\',{staticClass:"diagram"},[_vm._v("\\nmyService->DockerDeamon: start container\\nRegistrator--\x3eDockerDeamon: listen\\nRegistrator->etcd: writes an entry\\nSkyDNS--\x3eetcd: updates dns\\nLogspout--\x3eDockerDeamon: read logs\\n")]),_vm._v(" "),_c(\'p\',[_vm._v("The big advantage with this setup is that both the service discovery and the log shipping (through logspout) are completely decoupled from the application and still everything is dockerized - no further requirements on the host.")]),_vm._v(" "),_c(\'p\',[_vm._v("The simplified elasticsearch systemd-unit file can look like this:")]),_vm._v(" "),_c(\'pre\',[_c(\'code\',{pre:true,attrs:{"class":"bash"}},[_vm._v("\\n[Unit]\\nDescription=ElasticSearch service\\nAfter=docker.service\\n\\n[Service]\\nTimeoutSec=0\\nEnvironmentFile=/etc/environment\\n\\nExecStartPre=/usr/bin/mkdir -p /vol/data/elasticsearch\\nExecStartPre=/usr/bin/docker pull dockerfile/elasticsearch\\n\\nExecStart=/bin/bash -c \'\\\\\\n  exec docker run \\\\\\n  --name %p-%i \\\\\\n  -h `hostname` \\\\\\n  --publish 9200:9200 \\\\\\n  --publish 9300:9300 \\\\\\n  --volume /vol/data/elasticsearch:/usr/share/elasticsearch/data \\\\\\n  -e SERVICE_ID=%p%i \\\\\\n  -e ES_HEAP_SIZE=512M \\\\\\n  --dns ${COREOS_PRIVATE_IPV4} \\\\\\n  --dns-search=example.local \\\\\\n  elasticsearch:1.5.2 \\\\\\n  elasticsearch \\\\\\n  --node.name=%p-%i \\\\\\n  --cluster.name=logstash \\\\\\n  --network.publish_host=${COREOS_PRIVATE_IPV4} \\\\\\n  --discovery.zen.ping.multicast.enabled=false \\\\\\n  --discovery.zen.ping.unicast.hosts=elasticsearch-9200.staging.example.local\'\\n\\nExecStop=/usr/bin/docker stop %p-%i\\nExecStop=/usr/bin/docker rm %p-%i\\n\\n[X-Fleet]\\nConflicts=%p@*.service\\n")]),_vm._v("\\n")]),_vm._v(" "),_c(\'p\',[_vm._v("It\'s just a simple reference to the unicast host of the \\"load balanced\\" skydns image route. Because one of the nice out of the box features of skydns is that it provides automatically round robin balancing of multiple registered docker-container from the same docker-image.")]),_vm._v(" "),_c(\'p\',[_c(\'a\',{attrs:{"href":"https://github.com/Pindar/coreos-demo/releases/tag/v0.2"}},[_vm._v("You can find the updated code about the rsyslog/elasticsearch/kibana setup on github")]),_vm._v(".")]),_vm._v(" "),_c(\'hr\'),_vm._v(" "),_c(\'p\',[_vm._v("And because I like it this is written with "),_c(\'a\',{attrs:{"href":"https://stackedit.io/"}},[_vm._v("StackEdit")]),_vm._v(".")])]) }]',component:{data:function(){return{templateRender:null}},render:function(e){return this.templateRender?this.templateRender():e("div","Rendering")},created:function(){this.templateRender=function(){var e=this.$createElement;this._self._c;return this._m(0)},this.$options.staticRenderFns=[function(){var e=this,t=e.$createElement,n=e._self._c||t;return n("div",{staticClass:"dynamicMarkdown"},[n("p",[e._v("In my previous post about "),n("a",{attrs:{href:"http://www.itnotes.de/coreos/deployment/tools/infrastructure/aws/docker/fleet/2015/04/03/how-to-setup-rsyslog-elasticsearch-kibana-on-coreos/"}},[e._v("How to setup rsyslog, elasticsearch and kibana on CoreOS and AWS")]),e._v(" I used some custom scripts in order each service discovers all the required ones. E.g. I wrote my own announcement mechanism which polluted all the systemd unit files of the services. The disadvantage of my first approach is clear: it's mixing responsibilities.")]),e._v(" "),n("p",[e._v("In times of microservices and single responsibilities it has to be a better way to deal with it and in fact after doing some research (also talking with pkircher on the coreos IRC channel) I came up with the following:")]),e._v(" "),n("ol",[n("li",[n("a",{attrs:{href:"https://github.com/gliderlabs/registrator"}},[e._v("Registrator")]),e._v(" (as docker container) runs on each server once and automatically register/deregisters services for Docker containers based on published ports and metadata from the container environment.")]),e._v(" "),n("li",[n("a",{attrs:{href:"https://github.com/skynetservices/skydns"}},[e._v("SkyDNS")]),e._v(" (as docker container) runs on each server once and provides DNS to discover available services.")]),e._v(" "),n("li",[n("a",{attrs:{href:"https://github.com/gliderlabs/logspout"}},[e._v("Logspout")]),e._v(" (as docker container) runs also on each server once and ships docker logs to a centralized syslog server.")])]),e._v(" "),n("p",[e._v("When a service comes online the following happens:")]),e._v(" "),n("div",{staticClass:"diagram"},[e._v("\nmyService->DockerDeamon: start container\nRegistrator--\x3eDockerDeamon: listen\nRegistrator->etcd: writes an entry\nSkyDNS--\x3eetcd: updates dns\nLogspout--\x3eDockerDeamon: read logs\n")]),e._v(" "),n("p",[e._v("The big advantage with this setup is that both the service discovery and the log shipping (through logspout) are completely decoupled from the application and still everything is dockerized - no further requirements on the host.")]),e._v(" "),n("p",[e._v("The simplified elasticsearch systemd-unit file can look like this:")]),e._v(" "),n("pre",[n("code",{pre:!0,attrs:{class:"bash"}},[e._v("\n[Unit]\nDescription=ElasticSearch service\nAfter=docker.service\n\n[Service]\nTimeoutSec=0\nEnvironmentFile=/etc/environment\n\nExecStartPre=/usr/bin/mkdir -p /vol/data/elasticsearch\nExecStartPre=/usr/bin/docker pull dockerfile/elasticsearch\n\nExecStart=/bin/bash -c '\\\n  exec docker run \\\n  --name %p-%i \\\n  -h `hostname` \\\n  --publish 9200:9200 \\\n  --publish 9300:9300 \\\n  --volume /vol/data/elasticsearch:/usr/share/elasticsearch/data \\\n  -e SERVICE_ID=%p%i \\\n  -e ES_HEAP_SIZE=512M \\\n  --dns ${COREOS_PRIVATE_IPV4} \\\n  --dns-search=example.local \\\n  elasticsearch:1.5.2 \\\n  elasticsearch \\\n  --node.name=%p-%i \\\n  --cluster.name=logstash \\\n  --network.publish_host=${COREOS_PRIVATE_IPV4} \\\n  --discovery.zen.ping.multicast.enabled=false \\\n  --discovery.zen.ping.unicast.hosts=elasticsearch-9200.staging.example.local'\n\nExecStop=/usr/bin/docker stop %p-%i\nExecStop=/usr/bin/docker rm %p-%i\n\n[X-Fleet]\nConflicts=%p@*.service\n")]),e._v("\n")]),e._v(" "),n("p",[e._v('It\'s just a simple reference to the unicast host of the "load balanced" skydns image route. Because one of the nice out of the box features of skydns is that it provides automatically round robin balancing of multiple registered docker-container from the same docker-image.')]),e._v(" "),n("p",[n("a",{attrs:{href:"https://github.com/Pindar/coreos-demo/releases/tag/v0.2"}},[e._v("You can find the updated code about the rsyslog/elasticsearch/kibana setup on github")]),e._v(".")]),e._v(" "),n("hr"),e._v(" "),n("p",[e._v("And because I like it this is written with "),n("a",{attrs:{href:"https://stackedit.io/"}},[e._v("StackEdit")]),e._v(".")])])}]}}}}}}]);